\subsection{Application Performance}
\label{subsec:application}

In this section, we demonstrate that \sys{} can significantly improve the performance of real-world applications without modifying the code.
Rsocket~\cite{rsockets} fails to run the following applications, so we compare the performance with Linux and LibVMA~\cite{libvma}.

\subsubsection{Nginx HTTP Server}
\quad

To test a typical Web service scenario where the clients come from the network and served within a host, we use Nginx~\cite{nginx} as a reverse proxy between an HTTP request generator and an HTTP response generator.
Nginx and the response generator are in a same host, while the request generator is in a different host.
The generators use a persistent TCP connection to communicate with Nginx.
In Figure A, the request generator measures the time from sending an HTTP request to receiving the whole response.

Figure: latency vs request size.

%In Figure B, to test the how Nginx throughput scales with multiple cores, we run Nginx with a fixed number of worker threads and response size 1KB.
%The request generator sends multiple HTTP requests in parallel, and we use a sufficient number of generator threads to saturate Nginx throughput.
%Figure B: throughput scalability with number of cores.

\subsubsection{Redis Key-Value Store}
\quad

Redis~\cite{redis}

Figure: line chart, y axis: throughput, lines: (intra-, inter-) x (\sys{}, libvma, Linux). x axis: number of concurrent clients.

Utility: redis-benchmark.
Key point: concurrency low: test latency, concurrency high: test throughput.

%\subsection{Real-time Stream Processing}

%Apache Flink~\cite{carbone2015apache} (need to turn off durability on disk)

%Scenario: Word Count (distributed system with one source, two mappers and one reducer)

%Metrics: Latency, throughput

\subsubsection{ZeroMQ Message Queue}
\quad

Figure: line chart, y axis: latency, lines: (intra-, inter-) x (\sys{}, libvma, Linux), x axis: msg size.

Utility: zeromq official test zeromq\_lat.
Key point: latency is low.

\subsubsection{Network Function Pipeline}
\quad

64-byte packets in \emph{pcap} format originate from an external packet generator, pass through the network function (NF) pipeline, and sends back to the packet generator.
We implement each NF as a process that inputs packets from \emph{stdin}, updates local counters, and outputs to \emph{stdout}.
For Linux, we use \emph{pipe} and \emph{TCP socket} to connect NF processes inside a host.
Figure~\ref{fig:eval-tun-tput} shows that the throughput of \sys{} is 15x and 20x of Linux pipe and TCP socket, respectively.
It is even close to a state-of-the-art NF framework, NetBricks~\cite{panda2016netbricks}.

%\subsubsection{GraphX on Spark}
%\quad

%Two nodes run distributed PageRank.
%Test elapsed time per iteration with \sys{}, libvma and Linux. (Only need three numbers, no figure.)