\section{Applications}
\label{sec:application}



\begin{table*}[t]
	\centering
	\scalebox{0.88}{
		\begin{tabular}{l|c|ccc|cc|ccc|}
			\hline
			Category	& \multicolumn{1}{c|}{Linux Opt.} & \multicolumn{3}{c|}{New Kernel Stack} & \multicolumn{2}{c|}{User-space Packet} & \multicolumn{3}{c|}{User-space Socket} \\
			\hline
			System	& FastSocket & IX & MegaPipe & StackMap & Arrakis & FreeFlow & mTCP & libvma & SocksDirect \\
			\hline
			\hline
			Socket-like API & \yes & & \yes & \yes & \yes & & \yes & \yes & \yes \\
			\hline
			Linux Compatible & \yes & & & & & & & \yes & \yes \\
			\hline
			Process Isolation & \yes & \yes & \yes & \yes & \yes & \yes & \yes & \yes & \yes \\
			\hline
			\hline
			Kernel Bypass & & & & & \yes & \yes & \yes & \yes & \yes \\
			\hline
			Cooperative Multitasking & & & & & & & & & \yes \\
			\hline
			Zero Copy & & \yes & & \yes & \yes & \yes & & & \yes \\
			\hline
			\hline
			NIC-bypass IPC & \yes & & \yes & \yes & & \yes & \yes & & \yes \\
			\hline
			RDMA as Transport & & & & & & \yes & & & \yes \\
			\hline
			\hline
			Scalable Socket Creation & \yes & \yes & \yes & \yes & \yes & \yes & \yes & & \yes \\
			\hline
			Lock-free Multi-thread & & & & & & & & & \yes \\
			\hline
			Scale to Many Sockets & \yes & \yes & \yes & \yes & & & \yes & & \yes \\
			\hline
		\end{tabular}
	}
	\caption{Comparison of high performance socket systems.}
	\label{tab:related-work}
	\vspace{-10pt}
\end{table*}

In this section, we demonstrate that \sys{} can significantly improve the performance of real-world applications without modifying the code.


\subsection{Network Function}

Network Function Virtualization is prevalent and widely used in modern datacenters. We build up a chain of Network Functions (NF) with different lengths in one host. Each NF in the chain runs as a process and is pinned on one CPU core. It receives packets from the predecessor, modifies one byte of each packet, then sends them to the successor. We compare the performance of \sys{} with Linux socket and NetBricks~\cite{panda2016netbricks}, a highly optimized NF framework. Figure~\ref{fig:eval-tun-tput} shows that our \sys achieves performance that is comparable with NetBricks and scalable with number of cores.



\subsection{Web Application}
For web applications, we conduct experiment for a widely used scenario: One load balancer is connected with the backend web service, while the web service accesses the key value store for multiple round-trips.

Figure \ref{fig:eval-nginx-multiround} shows the end-to-end latency with different number of round-trips between the web service and key value store. As we measured, the Linux socket takes 69\% of the total CPU time before using \libipc. Since the intra-server latency of \sys{} is 30x lower than Linux socket, the end-to-end latency of the system with \sys{}  is 1/3 of that of original Linux socket.



%, Nodejs~\cite{nodejs} and memcached~\cite{memcached}

%\begin{itemize}
%	\item Figure~\ref{fig:eval-nginx-short}: Many short-lived connections. %Nginx $\rightarrow$ Nodejs, Nodejs access memcached once.
%	\item Figure~\ref{fig:eval-nginx-multiround}: Each connection, backend %interact extensively. (Nodejs access memcached multiple round trips.)
%\end{itemize}


%\subsection{Real-time Stream Processing}

%Apache Flink~\cite{carbone2015apache} (need to turn off durability on disk)

%Scenario: Word Count (distributed system with one source, two mappers and one reducer)

%Metrics: Latency, throughput

%\subsection{Machine Learning}

%Tensorflow~\cite{abadi2016tensorflow}

%Scenario: (Distributed Tensorflow) Parameter server and worker on a same server.

%Metrics: Time per iteration