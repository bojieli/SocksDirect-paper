\section{Architecture}
\label{sec:architecture}

To remove the overhead of context switch and centralized coordination while preserving the semantics and isolation of Linux system calls, we rethink the OS architecture and propose four design principles:

\textbf{Performance-critical OS functions run in user-mode library.}
Inspired by Library Operating System~\RED{(cite)} and user-mode network stacks~\RED{(cite)}, we move most OS functions from the kernel to user mode, \textit{i.e.}, file system and network sockets. We leverage multiple queues in contemporary NICs and NVMe SSDs to enable user-space direct access to network and storage. The kernel is still responsible for process creation, scheduling, virtual memory and device management, but no longer on the critical path of performance.

To maintain compatibility with existing Linux applications, we design a user-mode library \libipc as a drop-in replacement of the system call wrappers in the GNU C library (glibc). \libipc implements file system and network socket functions in user mode, and adds a wrapper to other system calls to track process creation and memory allocation.

\textbf{Minimize synchronization and memory sharing.}
For multi-core and multi-server scalability, we use message passing for inter-process communication and reduce state sharing to the most extent. We categorize Linux socket operations into partitionable~\cite{partitionable} and non-partitionable ones. We say an operation is partitionable if it only changes states local to a process (\textit{e.g.} assigning file descriptors) or between a pair of writer and reader processes (\textit{e.g.} sending a message). For non-partitionable operations (\textit{e.g.} load balancing new connections to listening processes), \libipc revisits the idea of \textit{monitor process}~\cite{hoare1974monitors} and delegates coordination to the monitor process, because delegation is faster than mutual exclusion~\cite{roghanchi2017ffwd}.

We develop a high performance lockless shared memory queue (Sec.\ref{subsec:lockless-queue}) to enable two application processes or one application process and the monitor process to communicate with each other directly. The Linux kernel provides memory isolation among different shared-memory queues. To reduce memory footprint and polling overhead, all socket connections between two processes are multiplexed through one lockless queue. In most cases, event polling and notifications are done locally (Sec.\ref{subsec:epoll}). As a result, only process initialization and connection setup are coordinated by the monitor.

\textbf{Design for the common and prepare for the worst.}
As discussed in Sec.\ref{subsec:challenges}, sockets can be shared among threads and processes. To ensure correctness for concurrent access, mutual exclusion would sacrifice the common-case one-to-one communication performance. To avoid such synchronization overhead, \libipc creates a queue between each pair of sender and receiver processes, and ensures receive ordering, liveness and starvation-free in all scenarios. (Sec.\ref{subsec:fork}).

\textbf{Utilize hardware for performance.}
To achieve zero-copy for sending and receiving large buffers inside a same server, we utilize the virtual memory in CPU and modify page mapping on send and receive (Sec.\ref{subsec:zerocopy}). For inter-server communication, we first check if the peer supports RDMA. If so, to achieve zero-copy and kernel-bypass for inter-server communication, \libipc uses one-sided RDMA~\cite{mitchell2013using} to offload the network stack to NIC hardware. Otherwise, \libipc uses libvma~\cite{libvma} to implement socket and TCP in user-space, while offload connection multiplexing to the NIC (Sec.\ref{sec:rdma}). For storage, \libipc utilizes SPDK~\cite{spdk} to create a hardware queue for each process (Sec.\ref{sec:implementation}).


%\RED{Why do we take the idea of Library OS? Every design choice should have rationale, otherwise the paper would look like a technical report.}
%\sys takes the idea of Library Operating System \RED{(cite)}. All the threads are treated as separated processes in our design. All function calls to the GNU C library is redirected to our user-mode library \libipc.

%\libipc leverages message passing to communicate with other processes to conduct inter-process communication and coordination of the resources of the operating system, i.e., file system, networking (sockets) in user-mode. We take advantage of the unmodified Linux Kernel for process creation and isolation, scheduling and memory management.

%To make a high performance design of \libipc, we treat processes as a distributed system and separate the Linux API to scalable and non-scalable parts. For the scalable parts eg. assign file descriptor, the \libipc of each process settle them individually. For the non-scalable parts, \libipc revisit the idea of a single monitor process on each machine to tackle the coordination problem without the overhead of traditional distributed systems.

%We noticed that the read and write between two processes can be highly scalable if two process communicate with each other directly with a shared memory queue. As a result, only the connection setup is coordinated by the monitor, which alleviate the workload of the monitor. The permission of Linux Kernel could provide isolation for different connections. RDMA is used in our design for inter-process communication across multiple machines.
