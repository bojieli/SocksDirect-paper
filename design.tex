\section{Inter-Process Socket in a Server}
\label{sec:intra-server}

\subsection{Scaling to Billions of Connections}
\label{subsec:socket-api}

The key to socket scalability is to minimize synchronization and memory sharing by making communications explicit via message passing. Because multiple threads in a process share memory space, we treat each thread as a separated process and use thread-specific storage to save states in \libipc. In the following text, unless explicitly mentioned, we refer to both processes and threads as processes.


\subsubsection{Connection Management}
\label{subsubsec:connection_management}

We take the idea of \cite{roghanchi2017ffwd} and use a dedicate monitor to avoid mutual exclusion in current Linux kernel. For instance, sockets provides \textit{SO\_REUSEPORT} as one flag when sockets created. When this flag is enabled, multiple process on one host could listen to the same port and the incoming connections are dispatched to one of those. Nginx use this option to enable multiple worker processes listen on the same port for load balancing. In Linux kernel, mutual exclusion is used for processes to compete the incoming connections while in our design monitor process is responsible for choosing a process to handle it by message passing.

In order to achieve high scalability, we separate scalable operations to different processes. In Linux kernel, file descriptor (fd) allocation is handled by mutual exclusion in kernel space. To avoid the overhead of contention, \libipc enable the file descriptor allocation by individual process and when a connection is setup, the other peer of the connection gets notified of the file descriptor number by message passing. Since we treat different threads in one process as different processes, we allocate file descriptor of different ranges to each of them to avoid collision. Since file descriptor is managed separately by each process, it is possible that a file descriptor is reused after the connection is closed. Our solution is that resources of a file descriptor is not released until an ACK is received for the close operation.

Generally, each process in our design is treated as an endpoint in the network. Figure \ref{fig:conn-setup-close} shows the process of connection setup and close. When \textit{socket} is called, the process itself allocate per fd resources. When \textit{listen} is called, monitor is notified of port occupation. During the \textit{connect} operation, monitor first chooses one of the processes listen on this port then coordinates the creation of the shared memory between the two processes and notifies each other of the new connection. When \textit{close} happens, both of the endpoint notify each other and monitor is responsible to destroy the shared memory between them. 

\begin{figure}[t]
	\centering
	\includegraphics[width=0.3\textwidth]{images/fixme}
	\caption{This figure shows the flow of connection setup and connection close.}
	\label{fig:conn-setup-close}
\end{figure}


\subsubsection{Data Transmission}
\label{subsubsec:data_trans}

To scale our system, as stated in section \ref{sec:architecture}, each processes transmit data directly without notifying monitor. As stated in section \ref{subsec:challenges}, memory footprint is critical to the overall performance of our system. For modern applications such as Nginx, asynchronous IO and epoll are widely used. The design of Linux kernel allocate a buffer for each of the file descriptor for these applications will lead to lots of cache miss due to the random access of different queues. Besides, in Linux, two cache migration are happened:1. set the bitmap of the epoll event 2. sender pushes the data into the buffer.

In order to reduce memory usage and improve cache efficiency, \libipc choose to use one shared memory lockless-queue for all the connections between two processes. Since it reduces random memory access, the cache miss is reduced. For event-driven programming i.e. epoll, only one cache migration is required when receiver pulls the data from the shared memory.

In order to support read/write operation without epoll i.e. not all the messages in the queue is polled by the receiver. We need to enable ``pop'' a message in the middle of the queue. To avoid starvation when all the slots in the queue is used, we need to assign a per-fd slot in case of the receiver blocks on the read operation of that fd. To tackle the variable size of messages, we allocate a dedicated memory pool for the data of the message and only the pointer of the message is stored in the lockless queue. In order to close the connection by receiver while sender is continually transmitting data, our design has a separate ``emergency queue'' to notify the sender the end of the connection.

Generally, for data transmission. In the shared memory between two processes, \libipc prepares a multiplexed queue for all the connections with ability of popping items in the middle of it, an ``emergency queue'' for instant messages and a memory pool to store data.

fd multiplexing

How the socket works. A table show the process of using socket:

\begin{itemize}
	\item Process and thread creation. (fork, pthread\_create)
	\item Socket initialization.
	\item Connection setup.
	\item Data transmission.
\end{itemize}


Data structure in each process. Data structure in the monitor process.

Need a figure to show the lifecycle (message passing flow) of a socket connection. Three sub-figures:


	 \textbf{Socket initialization.}
	  
	 \textbf{Connection setup. (accept scheduling)}
	 
	 \textbf{Data transmission.}
	 
	 Discuss epoll.
\begin{itemize}
	\item Pick from the middle of the Q
	\item Starving (per fd slot)
	\item emergency Q
\end{itemize}

    \textbf{Close \& ACK}


\subsection{Scaling Shared Socket}
\label{subsec:fork}

Process fork and thread creation are essential mechanisms to enable parallelism in modern applications. 
However, as stated in \ref{subsec:challenges}, fork and thread creation makes socket a producer-consumer model. With a traditional mutual exclusion solution, the multi-process scalability of socket is limited.

To this end, we maximize the common-case performance while keeping compatibility with Linux socket semantics.
We make the following observations:
\begin{enumerate}
	\item Fork and thread creation are not frequent in high performance applications, compared to connection setup and data transmission.
	\item It is uncommon that several processes receive concurrently from one shared socket, because the streaming semantics of socket makes concurrent receivers hard to avoid receiving incomplete messages. For such producer-consumer scenarios, message brokers~\cite{hintjens2013zeromq,rabbitmq2017rabbitmq,kreps2011kafka} are typically used.
\end{enumerate}

Based on the second observation, we propose the following requirements to maximize the common-case performance:
\begin{enumerate}
 \item \textbf{Synchronization-free.} With multiple potential senders and receivers, if only one pair of sender and receiver is active, the throughput and latency should be comparable with that of a sender-receiver pair.
 \item \textbf{Multi-sender scalability.} Multiple processes may send data (\textit{e.g.} log) concurrently through a shared socket. For multiple active senders and one receiver, if receiver is not a bottleneck, the throughput is supposed to scale, rather than dropping heavily due to mutual exclusion.
 \item \textbf{Self-stabilization.} Previous access patterns shall not have follow-up effect on current performance. For example, applications may implicitly transfer a socket from one process to another (\textit{e.g.} from master to worker). These operations may slow down the system temporarily, but after that the throughput is supposed to converge to common-case.
\end{enumerate}

For compatibility with Linux semantics, we also need to ensure message ordering and liveness:
\begin{enumerate}
\item \textbf{Single receiver ordering.} For a specific pair of sender and receiver, the received messages have the same ordering as they were sent.
\item \textbf{Multiple receiver ordering.} The order of \texttt{send} and \texttt{recv} operations for one sender and multiple receivers should be linearizable. If receiver $R_1$ already receives $D_1$, then receiver $R_2$ calls \texttt{recv} and gets $D_2$, we guarantee that $D_1$ is sent before $D_2$.
\item \textbf{Deadlock-free.} If a socket buffer is not empty when \texttt{recv} is called by one or more receivers, at least one receiver should get data.
\item \textbf{Starvation-free.} If a sender keeps sending, any receiver trying to \texttt{recv} will eventually get data.
\end{enumerate}

Our scalable socket design can be divided into four parts: a) \texttt{send} and \texttt{recv}, b) adding new senders and receivers (\texttt{fork} and \texttt{pthread\_create}), c) connection creation and d) connection close.

\subsubsection{Send/Recv Operation}
\label{subsubsec:fork_rdwr}

In this section, we assume that a socket is already connected and the number of senders and receivers are constant. In order to avoid synchronization and achieve high scalability, we create lock-free shared-memory queues between every pair of sender and receiver. The queues form a bipartite graph between senders and receivers. Each receiver polls messages from all senders in round-robin order.
%Figure \ref{fig:fork-bipartitegraph} shows a sample of the shared-memory buffers between senders and receivers for one connection.

To ensure multiple receiver ordering and avoid synchronization, each sender designates one receiver with exclusive access to the socket. In common cases with one active receiver, the performance could achieve that of one-to-one shared-memory communication. It is challenging for the sender to choose a receiver, since the chosen one may not call \texttt{recv}, while other receivers may be under starvation. When a non-designated receiver tries to receive from the socket, it sends a \textit{takeover request} to the sender. To avoid starvation, the sender processes takeover requests in FIFO order.

A challenge arise when there is remaining data in the queue when a receiver requests to take over the socket. We need to ensure that all the remaining data can be received by the new receiver. Because multiple sockets share a queue from sender to each receiver, and different sockets have different designated receivers, the new receiver cannot access the queue from the old receiver directly. Instead, the remaining data needs to migrate from the old queue to the new queue. When the sender processes a takeover request, it first forwards it to the current receiver. Upon receiving takeover request, the current receiver returns all remaining data to sender via \textit{takeover completion} messages, while sender forwards the messages to the new receiver. During migration of remaining data, the sender blocks \texttt{send} operations and takeover requests to ensure message ordering.

Another challenge is that when a receiver should send a takeover request. Each receiver maintains a flag locally to indicate whether it is designated by the sender. The flag is flipped when the receiver gets takeover request or completion from sender. When a receiver tries to \texttt{recv} and finds itself not designated, the receiver sends a takeover request to sender. Before the receiver becomes designated, the takeover request is sent only once.

%\begin{figure}[t]
%	\centering
%	\includegraphics[width=0.3\textwidth]{images/fixme}
%	\caption{This figure shows a stable connection handled by multiple senders and receivers.}
%	\label{fig:fork-bipartitegraph}
%\end{figure}

\subsubsection{Fork and Thread Creation}
\label{subsubsec:fork_fork}

Fork is a procedure that new processes attach to existing connections. Logically, there are four different cases when fork happens for one process:
\begin{enumerate}
	\item The process itself is the sender side of the connection and it forks.
	\item The process itself is the sender of the connection while one of the receiver folks.
	\item The process itself is the receiver side of the connection and it forks.
	\item The process itself is the receiver of the connection while one of the sender folks.
\end{enumerate}

The general process of fork is that after monitor is notified of the fork, it creates shared memory between the newly created process and all the processes which previously have connections with the parent process. The key challenge lies in the fork is that how to deal with the existing data in the connection to guarantee the order requirements.

For the cases 2 and 3, we could adopt the idea of ``takeover message'' as stated in Sec.~\ref{subsubsec:fork_rdwr}. Each of the forked new process creates a new queue for its old connection. When the receiver side call read for the connection, a ``takeover message'' is emit and the sender designate the new process as the exclusive receiver and poll all the data in the old queue to the receiver which sends ``takeover message''.

However, It is more complicated for case 1 and case 4. We cannot leverage the ``takeover message'' trick since the two senders may emit data in parallel and we cannot guarantee all the data sent prior to fork is consumed before to that following the fork by new processes. It is not efficient to block all the senders before old data is consumed either.

Our solution is to when the sender side forks, we preserve the old shared memory and create two new shared memory for each receiver and connection them to the new sender processes separately. All the receiver side is notified of the folk and keep a tree data structure of all the shared memories.The two new sender transmit all the new messages to the newly created shared memory separately. When the receiver tries to retrieve data, it first try the old shared memory, if it is empty, it will remove the old shared memory and promote the child of this memory for the read request. 

Things become much more complicated when cases 1,4 happens after cases 2,3 happening. After receiver forks, the unique sender is responsible for receiving ``takeover message'' and resend the data to new receivers. However, if sender forks following the receiver forks, according to the methods we mentioned above, there is no sender responsible for processing ``takeover message''. Our solution is that we require the receivers to poll the data from the old shared memory queue and compete for data. Since this case rarely happens, the performance of the overall design is not affected.

\subsubsection{Connection Creation}
\label{subsubsec:fork_new}

A connection created after \texttt{fork} cannot be accessed by its parent or child process, while a connection created by a thread can be accessed by all threads in the same process. Each connection is identified by a file descriptor, which is an integer assigned by \libipc. To minimize state sharing, \libipc assigns a unique file descriptor space to each thread, so each thread can allocate file descriptors locally and determine which thread a file descriptor belongs to. During connection creation, \libipc does not share the file descriptor eagerly with other threads, because most threads in existing applications do not use connections created by other threads.

If the application accesses a thread-local file descriptor, \libipc processes it locally. Otherwise, \libipc sends a message to the owner thread and requests sharing the file descriptor. This procedure is exactly the same as sharing existing connections during thread creation (Sec.~\ref{subsubsec:fork_fork}). The sharing procedure needs only once per connection and thread. Sharing existing connections eagerly during thread creation is an optimization. First, children threads are more likely to use existing connections than siblings. Second, batch processing improves performance.

\subsubsection{Connection Close}
\label{subsubsec:fork_close}

Close is the operation that all of the processes leave the connection. The synchronization is  especially challenging since all the processes are run in parallel. One challenge lies in file descriptors are managed by decentralized processes and are possibly reused. One process close a connection while the others are doing compute intensive tasks is a case. It is possible that the file descriptor of the old process is reused and a new connection is setup with the same file descriptor. The other process may notice the close of the old connection and also call close on its own side, which lead to the new connection setup by the previous process closed due to the match of same file descriptor. 

To satisfy the synchronization requirements, the close function call is all completed by message passing. The caller of close need to wait for ACK from all the other peers before release resources. i.e. the status of the connection.

Another challenge lies in the close of a connection is that close is a broadcast operation while send/receive is sent to a specific process. Besides, fork and close are immutable operations while the scalability requirements of the system impose the constraint that all the operations run asynchronously. As a result, a rule to determine the partial order is required.

In \libipc, we make the choice that the order of fork and close is determined at the start point of the fork operation and the end point (after receiving all the ACKs). By making this choice, when a process waiting fork close ACK encounters fork message, it could send a separate close request to newly created process, which guarantees all the processes closed.
  
Key point: Coordination in shared socket.

Clock pointer (simple)

Takeover (compare with \ref{subsec:socket-api})

Read Lock

Tree

Fork \& Close interleaving

\subsection{Process Multiplexing}
\label{subsec:process-mux}

To minimize context switch, \sys{} runs in user mode and uses cooperative multitasking to multiplex processes on CPU cores. Coordination and delegation based on message passing also requires processes to respond messages promptly. However, processes may execute application code without calling \libipc for a long time or may block on a kernel system call.

To this end, message passing initiators first poll the receive queue for a while. If no reply, it sends a Linux \texttt{signal} to the receptor and wake up the process. The signal handler, registered by \libipc, first determines whether the process is executing application or \libipc code. If in application, the signal handler processes emergent messages immediately, then return control to the application. Otherwise, the signal handler does nothing and \libipc will check emergent messages before returning control to the application. Because \libipc is designed to be fast and non-blocking, message passing initiators will soon receive the response. This signal mechanism is analogous to interrupts in operating systems.


Monitor detect process death (via control socket SIGHUP) and notify endpoints.

Blocking operation: sched\_yield.


\subsection{Zero Copy}
\label{subsec:zerocopy}

\begin{figure}[t]
	\centering
	\includegraphics[width=0.3\textwidth]{images/fixme}
	\caption{Zero-copy theory of operation.}
	\label{fig:zerocopy}
\end{figure}

The main challenge for zero copy is to maintain the semantics of socket API. The sender may write the send buffer after non-blocking \texttt{send}, and the receiver does not know the receive buffer before \texttt{recv}.
Fortunately, the virtual memory provides a layer of indirection, so we can remap virtual address of a buffer to another physical page, if the data occupies entire 4~KiB pages.
To this end, we wrap around \texttt{malloc} function and allocate 4~KiB aligned addresses for large allocations, so most buffers will align to page boundary.
If the size of send message is not a multiple of 4~KiB, the last chunk of data is copied on \texttt{send} and \texttt{recv}.

As shown in Figure~\ref{fig:zerocopy}, for \texttt{send} operation, \libipc{} invokes the kernel to get an encrypted physical address of send buffer and send the address to receiver via user-mode shared-memory queue.
The address is encrypted to prevent unsolicited mapping of arbitrary pages.
Because the sender may read the buffer after \texttt{send} or send the buffer to multiple receivers, the physical page cannot be remapped.
Additionally, \texttt{send} needs to write-protect the buffer because the receiver needs to read it.
On receiving side, \libipc{} invokes the kernel to remap the encrypted physical address to the application-provided receive buffer.
\texttt{recv} also needs to write-protect the buffer because it is shared by the sender and potentially multiple receivers.

A challenge arises when sender writes the buffer after \texttt{send}.
Existing zero-copy socket designs~\cite{thadani1995efficient,chu1996zero} use copy-on-write. Copy is required because the sender may read the non-written part of the page.
Because most applications reuse the buffer for subsequent send operations, copy-on-write is invoked in most cases, making zero-copy essentially useless on sender.
Our observation is that most applications overwrite entire pages of the send buffer via \texttt{recv} or \texttt{memcpy}, so it is unnecessary to copy old data when the first byte of the page is written.
Zero-copy \texttt{recv} remaps the buffer without triggering copy-on-write, so proxy applications can achieve zero copy.
For \texttt{memcpy}, we add preamble code to the function in both \libipc{} runtime and compiler inline library. If both source, destination addresses and the copy size are aligned to 4~KiB, and the destination address is write-protected by \libipc{}, the preamble code invokes the kernel to remap new pages to the destination address and disable write protection.
For compatibility, copy-on-write is still used for other write operations to protected buffers.

A second challenge is that page remapping requires the kernel to allocate and free pages for each \texttt{send} and \texttt{recv}. Page allocation in kernel acquires a global lock, therefore it is inefficient. Instead, \libipc{} manages a pool of free pages in each user-mode process.
We add to the kernel a system call to convert virtual addresses in the pool and encrypted physical addresses.
\libipc{} also tracks the origin of received zero-copy buffers.
After page remapping on sender \texttt{memcpy} and receiver \texttt{recv}, if the old physical page is from another process, \libipc{} sends a message to the origin process to return the buffer.


\section{Inter-Server Socket}
\label{sec:rdma}

RDMA if the remote side supports socket.

 libvma (lightweight user-mode stack).


One-sided  RDMA: credit-based ring buffer. Intra-server: valid-bit based ring buffer.


Remember: if the other endpoint is not RDMA capable, use libvma.

 It reserves the send buffer after \texttt{send} and releases it after send completion notification.
The application also delegates non-blocking receive operations along with receive buffers, so the NIC can DMA received data directly to the receive buffers, then notify the application that data is ready.
