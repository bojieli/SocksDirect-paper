\section{Inter-Process Socket in a Server}
\label{sec:intra-server}

\subsection{Scaling to Billions of Connections}
\label{subsec:socket-api}

The key to socket scalability is to minimize memory sharing by making communications explicit via message passing. Because multiple threads in a process share memory space, we treat each thread as a separated process and use thread-specific storage to save states in \libipc. In the following text, unless explicitly mentioned, we refer to ``processes and threads'' as ``processes''.

\begin{table*}[t]
\centering
\begin{tabular}{ll|ll|ll|ll}
	\hline
	\multicolumn{2}{c|}{Initialization} &
	\multicolumn{2}{c|}{Connection Mgmt} &
	\multicolumn{2}{c|}{Data Transmission} &
	\multicolumn{2}{c}{Process Mgmt} \\
	\hline
	API & Cat. &
	API & Cat. &
	API & Cat. &
	API & Cat. \\
	\hline
	\hline
	socket & Local &
	connect & NoPart &
	send(to,msg,mmsg) & P2P &
	\textit{fork} & NoPart \\
	\hline
	bind & NoPart &
	accept(4) & NoPart &
	recv(from,msg,mmsg) & P2P &
	\textit{pthread\_create} & NoPart \\
	\hline
    listen & Local &
    \textit{fcntl} & Local &
	\textit{write(v)} & P2P &
 	\textit{execve} & NoPart \\
	\hline
	socketpair & Local &
	(get,set)sockopt & Local &
	\textit{read(v)} & P2P &
 	\textit{exit} & P2P \\
	\hline
	getsockname  & Local &
	getpeername & P2P &
	\textit{close}, shutdown & P2P &
	\textit{sleep} & P2P \\
	\hline
	\textit{malloc} & Local &
	\textit{dup(2,3)} & P2P &
	\textit{select, poll} & Local &
	\textit{kill}   & P2P \\
	\hline
	\textit{epoll\_create} & Local &
	\textit{epoll\_ctl} & Local &
	\textit{epoll\_(p)wait} & Local &
	\textit{/proc fs} & NoPart \\
	\hline
\end{tabular}
\caption{Local, peer-to-peer (P2P) and non-partitionable (NoPart) Linux APIs that are related to socket and intercepted by \libipc{}. APIs in \textit{italic} indicate usages more than socket.}
\label{tab:socket-api}
\end{table*}


\subsubsection{Connection Management}
\label{subsubsec:connection_management}

We take the idea of \cite{roghanchi2017ffwd} and use a dedicate monitor to avoid mutual exclusion in current Linux kernel. For instance, sockets provides \textit{SO\_REUSEPORT} as one flag when sockets created. When this flag is enabled, multiple process on one host could listen to the same port and the incoming connections are dispatched to one of those. Nginx use this option to enable multiple worker processes listen on the same port for load balancing. In Linux kernel, mutual exclusion is used for processes to compete the incoming connections while in our design monitor process is responsible for choosing a process to handle it by message passing.

In order to achieve high scalability, we separate scalable operations to different processes. In Linux kernel, file descriptor (fd) allocation is handled by mutual exclusion in kernel space. To avoid the overhead of contention, \libipc enable the file descriptor allocation by individual process and when a connection is setup, the other peer of the connection gets notified of the file descriptor number by message passing. Since we treat different threads in one process as different processes, we allocate file descriptor of different ranges to each of them to avoid collision. Since file descriptor is managed separately by each process, it is possible that a file descriptor is reused after the connection is closed. Our solution is that resources of a file descriptor is not released until an ACK is received for the close operation.

Generally, each process in our design is treated as an endpoint in the network. Figure \ref{fig:conn-setup-close} shows the process of connection setup and close. When \textit{socket} is called, the process itself allocate per fd resources. When \textit{listen} is called, monitor is notified of port occupation. During the \textit{connect} operation, monitor first chooses one of the processes listen on this port then coordinates the creation of the shared memory between the two processes and notifies each other of the new connection. When \textit{close} happens, both of the endpoint notify each other and monitor is responsible to destroy the shared memory between them. 

\begin{figure}[t]
	\centering
	\includegraphics[width=0.3\textwidth]{images/fixme}
	\caption{This figure shows the flow of connection setup and connection close.}
	\label{fig:conn-setup-close}
\end{figure}


\subsubsection{Data Transmission}
\label{subsubsec:data_trans}

To scale our system, as stated in section \ref{sec:architecture}, each processes transmit data directly without notifying monitor. As stated in section \ref{subsec:challenges}, memory footprint is critical to the overall performance of our system. For modern applications such as Nginx, asynchronous IO and epoll are widely used. The design of Linux kernel allocate a buffer for each of the file descriptor for these applications will lead to lots of cache miss due to the random access of different queues. Besides, in Linux, two cache migration are happened:1. set the bitmap of the epoll event 2. sender pushes the data into the buffer.

In order to reduce memory usage and improve cache efficiency, \libipc choose to use one shared memory lockless-queue for all the connections between two processes. Since it reduces random memory access, the cache miss is reduced. For event-driven programming i.e. epoll, only one cache migration is required when receiver pulls the data from the shared memory.

In order to support read/write operation without epoll i.e. not all the messages in the queue is polled by the receiver. We need to enable ``pop'' a message in the middle of the queue. To avoid starvation when all the slots in the queue is used, we need to assign a per-fd slot in case of the receiver blocks on the read operation of that fd. To tackle the variable size of messages, we allocate a dedicated memory pool for the data of the message and only the pointer of the message is stored in the lockless queue. In order to close the connection by receiver while sender is continually transmitting data, our design has a separate ``emergency queue'' to notify the sender the end of the connection.

Generally, for data transmission. In the shared memory between two processes, \libipc prepares a multiplexed queue for all the connections with ability of popping items in the middle of it, an ``emergency queue'' for instant messages and a memory pool to store data.


\subsection{Lockless Shared Memory Queue}
\label{subsec:lockless-queue}


\begin{itemize}
	\item requirements: Shared memory, single writer and single reader.
	\item each slot 16 bytes
	\item Figure: two pointers, several isvalid items, data buffer
	\item pointer: local
	\item label -> flag
	\item isvalid meaning
	\item isdeleted: push clear bit, pick from middle (iterate from head to tail), pop (set pointer iterate...)
	\item It is common -> cite systems with memory fence
	\item data buffer: avoid memory fragmentation, fixed sized slots, chain, queue (lockless ring buffer)
	\item mention zero copy
\end{itemize}

As stated in section \ref{subsubsec:data_trans}, our lockless queue i.e. ring buffer is used for direct data transmission between two processes, and is used for message passing between process and the monitor. To recap, lockless queue in \libipc is used to support one-one connection in shared memory.

The structure of lockless queue shows in figure \ref{fig:locklessq-structure}. We leverage ring buffer as the data structure of the queue. Each slots of the queue is 16 bytes. Both sender and the receiver have a pointer stored locally. We denote the pointer of sender side as \textit{head}, and the receiver one as \textit{tail}. The sender pushes new items to the location pointed by head and increases the head while the receiver pops items according to its own tail and increases its tail.  In order to know whether the slot pointed by \textit{head} or \textit{tail} is available, we put a \textit{isvalid} flag in each of the slot. When sender pushes the item, the flag is set while when receiver pops the item, the flag is cleared.

In order to support ``pick'' from the middle of the queue, we add an additional ``isdel'' flag to each slot. When ``pick'' happens, ``isdel'' is set and ``isvalid'' is not changed. When receiver tries to pop an item from ``tail'', it iterate the ring buffer from tail and check ``isdel'' flag. If it is set, ``isvalid'' is set to false and ``tail'' is increased.
\begin{figure}[t]
	\centering
	\includegraphics[width=0.3\textwidth]{images/fixme}
	\caption{This figure shows the structure of lockless queue (contains shared memory, 2 local ptr, isvalid flag and isdel flag).}
	\label{fig:locklessq-structure}
\end{figure}


To support variable size of messages, we allocate a memory pool in shared memory and set the pointer in message queue to the element in memory pool. We divide memory pool to 1KB blocks. The IDs of the available blocks are organized in another queue and are pushed by receiver (Receiver pops the item and releases the memory) and are consumed by sender. If the size of message is larger 1KB, multiple blocks are used and chained as a linked list. By doing so, we could avoid memory fragmentation and reduce the memory management contention between sender and the receiver. 

It is common that the operation of the shared memory is protected by the \textit{memory fence} instruction in order to avoid the reorder caused by out-of-order execution on modern X86 CPU, which has expensive cost since it locks the memory bus. We make the observation that only write may be delayed according to the manual of Intel \cite{sewell2010x86,intel-manual}. By carefully adjusting the order of the instructions and removing \textit{memory fence}, the throughput of lockless queue could achieve 30M per second. 




\subsection{Scaling Shared Socket}
\label{subsec:fork}

Process fork and thread creation are essential mechanisms to enable parallelism in modern applications. 
However, as stated in \ref{subsec:challenges}, fork and thread creation makes socket a producer-consumer model. With a traditional mutual exclusion solution, the multi-process scalability of socket is limited.

To this end, we maximize the common-case performance while keeping compatibility with Linux socket semantics.
We make the following observations:
\begin{enumerate}
	\item Fork and thread creation are not frequent in high performance applications, compared to connection setup and data transmission.
	\item It is uncommon that several processes receive concurrently from one shared socket, because the streaming semantics of socket makes concurrent receivers hard to avoid receiving incomplete messages. For such producer-consumer scenarios, message brokers~\cite{hintjens2013zeromq,rabbitmq2017rabbitmq,kreps2011kafka} are typically used.
\end{enumerate}

Based on the second observation, we propose the following requirements to maximize the common-case performance:
\begin{enumerate}
 \item \textbf{Synchronization-free.} With multiple potential senders and receivers, if only one pair of sender and receiver is active, the throughput and latency should be comparable with that of a sender-receiver pair.
 \item \textbf{Multi-sender scalability.} Multiple processes may send data (\textit{e.g.} log) concurrently through a shared socket. For multiple active senders and one receiver, if receiver is not a bottleneck, the throughput is supposed to scale, rather than dropping heavily due to mutual exclusion.
 \item \textbf{Self-stabilization.} Previous access patterns shall not have follow-up effect on current performance. For example, applications may implicitly transfer a socket from one process to another (\textit{e.g.} from master to worker). These operations may slow down the system temporarily, but after that the throughput is supposed to converge to common-case.
\end{enumerate}

For compatibility with Linux semantics, we also need to ensure message ordering and liveness:
\begin{enumerate}
\item \textbf{Single receiver ordering.} For a specific pair of sender and receiver, the received messages have the same ordering as they were sent.
\item \textbf{Multiple receiver ordering.} The order of \texttt{send} and \texttt{recv} operations for one sender and multiple receivers should be linearizable. If receiver $R_1$ already receives $D_1$, then receiver $R_2$ calls \texttt{recv} and gets $D_2$, we guarantee that $D_1$ is sent before $D_2$.
\item \textbf{Deadlock-free.} If a socket buffer is not empty when \texttt{recv} is called by one or more receivers, at least one receiver should get data.
\item \textbf{Starvation-free.} If a sender keeps sending, any receiver trying to \texttt{recv} will eventually get data.
\end{enumerate}

Our scalable socket design can be divided into four parts: a) \texttt{send} and \texttt{recv}, b) adding new senders and receivers (\texttt{fork} and \texttt{pthread\_create}), c) connection creation and d) connection close.

\subsubsection{Send/Recv Operation}
\label{subsubsec:fork_rdwr}

In this section, we assume that a socket is already connected and the number of senders and receivers are constant. In order to avoid synchronization and achieve high scalability, we create lock-free shared-memory queues between every pair of sender and receiver. The queues form a bipartite graph between senders and receivers. Each receiver polls messages from all senders in round-robin order.
%Figure \ref{fig:fork-bipartitegraph} shows a sample of the shared-memory buffers between senders and receivers for one connection.

To ensure multiple receiver ordering and avoid synchronization, each sender designates one receiver with exclusive access to the socket. In common cases with one active receiver, the performance could achieve that of one-to-one shared-memory communication. It is challenging for the sender to choose a receiver, since the chosen one may not call \texttt{recv}, while other receivers may be under starvation. When a non-designated receiver tries to receive from the socket, it sends a \textit{takeover request} to the sender. To avoid starvation, the sender processes takeover requests in FIFO order.

A challenge arise when there is remaining data in the queue when a receiver requests to take over the socket. We need to ensure that all the remaining data can be received by the new receiver. Because multiple sockets share a queue from sender to each receiver, and different sockets have different designated receivers, the new receiver cannot access the queue from the old receiver directly. Instead, the remaining data needs to migrate from the old queue to the new queue. When the sender processes a takeover request, it first forwards it to the current receiver. Upon receiving takeover request, the current receiver returns all remaining data to sender via \textit{takeover completion} messages, while sender forwards the messages to the new receiver. During migration of remaining data, the sender blocks \texttt{send} operations and takeover requests to ensure message ordering.

Another challenge is that when a receiver should send a takeover request. Each receiver maintains a flag locally to indicate whether it is designated by the sender. The flag is flipped when the receiver gets takeover request or completion from sender. When a receiver tries to \texttt{recv} and finds itself not designated, the receiver sends a takeover request to sender. Before the receiver becomes designated, the takeover request is sent only once.

%\begin{figure}[t]
%	\centering
%	\includegraphics[width=0.3\textwidth]{images/fixme}
%	\caption{This figure shows a stable connection handled by multiple senders and receivers.}
%	\label{fig:fork-bipartitegraph}
%\end{figure}

\subsubsection{Fork and Thread Creation}
\label{subsubsec:fork_fork}

Fork is a procedure that new processes attach to existing connections. Logically, there are four different cases when fork happens for one process:
\begin{enumerate}
	\item The process itself is the sender side of the connection and it forks.
	\item The process itself is the sender of the connection while one of the receiver folks.
	\item The process itself is the receiver side of the connection and it forks.
	\item The process itself is the receiver of the connection while one of the sender folks.
\end{enumerate}

The general process of fork is that after monitor is notified of the fork, it creates shared memory between the newly created process and all the processes which previously have connections with the parent process. The key challenge lies in the fork is that how to deal with the existing data in the connection to guarantee the order requirements.

For the cases 2 and 3, we could adopt the idea of ``takeover message'' as stated in Sec.~\ref{subsubsec:fork_rdwr}. Each of the forked new process creates a new queue for its old connection. When the receiver side call read for the connection, a ``takeover message'' is emit and the sender designate the new process as the exclusive receiver and poll all the data in the old queue to the receiver which sends ``takeover message''.

However, It is more complicated for case 1 and case 4. We cannot leverage the ``takeover message'' trick since the two senders may emit data in parallel and we cannot guarantee all the data sent prior to fork is consumed before to that following the fork by new processes. It is not efficient to block all the senders before old data is consumed either.

Our solution is to when the sender side forks, we preserve the old shared memory and create two new shared memory for each receiver and connection them to the new sender processes separately. All the receiver side is notified of the folk and keep a tree data structure of all the shared memories.The two new sender transmit all the new messages to the newly created shared memory separately. When the receiver tries to retrieve data, it first try the old shared memory, if it is empty, it will remove the old shared memory and promote the child of this memory for the read request. 

Things become much more complicated when cases 1,4 happens after cases 2,3 happening. After receiver forks, the unique sender is responsible for receiving ``takeover message'' and resend the data to new receivers. However, if sender forks following the receiver forks, according to the methods we mentioned above, there is no sender responsible for processing ``takeover message''. Our solution is that we require the receivers to poll the data from the old shared memory queue and compete for data. Since this case rarely happens, the performance of the overall design is not affected.

\subsubsection{Connection Creation}
\label{subsubsec:fork_new}

A connection created after \texttt{fork} cannot be accessed by its parent or child process, while a connection created by a thread can be accessed by all threads in the same process. Each connection is identified by a file descriptor, which is an integer assigned by \libipc. To minimize state sharing, \libipc assigns a unique file descriptor space to each thread, so each thread can allocate file descriptors locally and determine which thread a file descriptor belongs to. During connection creation, \libipc does not share the file descriptor eagerly with other threads, because most threads in existing applications do not use connections created by other threads.

If the application accesses a thread-local file descriptor, \libipc processes it locally. Otherwise, \libipc sends a message to the owner thread and requests sharing the file descriptor. This procedure is exactly the same as sharing existing connections during thread creation (Sec.~\ref{subsubsec:fork_fork}). The sharing procedure needs only once per connection and thread. Sharing existing connections eagerly during thread creation is an optimization. First, children threads are more likely to use existing connections than siblings. Second, batch processing improves performance.

\subsubsection{Connection Close}
\label{subsubsec:fork_close}

Close is the operation that all of the processes leave the connection. The synchronization is  especially challenging since all the processes are run in parallel. One challenge lies in file descriptors are managed by decentralized processes and are possibly reused. One process close a connection while the others are doing compute intensive tasks is a case. It is possible that the file descriptor of the old process is reused and a new connection is setup with the same file descriptor. The other process may notice the close of the old connection and also call close on its own side, which lead to the new connection setup by the previous process closed due to the match of same file descriptor. 

To satisfy the synchronization requirements, the close function call is all completed by message passing. The caller of close need to wait for ACK from all the other peers before release resources. i.e. the status of the connection.

Another challenge lies in the close of a connection is that close is a broadcast operation while send/receive is sent to a specific process. Besides, fork and close are immutable operations while the scalability requirements of the system impose the constraint that all the operations run asynchronously. As a result, a rule to determine the partial order is required.

In \libipc, we make the choice that the order of fork and close is determined at the start point of the fork operation and the end point (after receiving all the ACKs). By making this choice, when a process waiting fork close ACK encounters fork message, it could send a separate close request to newly created process, which guarantees all the processes closed.
  
Key point: Coordination in shared socket.

Clock pointer (simple)

Takeover (compare with \ref{subsec:socket-api})

Read Lock

Tree

Fork \& Close interleaving

\subsection{Cooperative Multitasking}
\label{subsec:process-mux}

To minimize context switch, \sys{} runs in user mode and uses cooperative multitasking to multiplex processes on CPU cores. Coordination and delegation based on message passing also requires processes to respond messages promptly. However, processes may execute application code without calling \libipc for a long time or may block on a kernel system call.

To this end, message passing initiators first poll the receive queue for a while. If no reply, it sends a Linux \texttt{signal} to the receptor and wake up the process. The signal handler, registered by \libipc, first determines whether the process is executing application or \libipc code. If in application, the signal handler processes emergent messages immediately, then return control to the application. Otherwise, the signal handler does nothing and \libipc will check emergent messages before returning control to the application. Because \libipc is designed to be fast and non-blocking, message passing initiators will soon receive the response. This signal mechanism is analogous to interrupts in operating systems.


Monitor detect process death (via control socket SIGHUP) and notify endpoints.

Blocking operation: sched\_yield.


\subsection{Zero Copy}
\label{subsec:zerocopy}

\begin{figure}[t]
	\centering
	\includegraphics[width=0.3\textwidth]{images/fixme}
	\caption{Zero-copy theory of operation.}
	\label{fig:zerocopy}
\end{figure}

The main challenge for zero copy is to maintain the semantics of socket API. The sender may write the send buffer after non-blocking \texttt{send}, and the receiver does not know the receive buffer before \texttt{recv}.
Fortunately, the virtual memory provides a layer of indirection, so we can remap virtual address of a buffer to another physical page, if the data occupies entire 4~KiB pages.
To this end, we wrap around \texttt{malloc} function and allocate 4~KiB aligned addresses for large allocations, so most buffers will align to page boundary.
If the size of send message is not a multiple of 4~KiB, the last chunk of data is copied on \texttt{send} and \texttt{recv}.

As shown in Figure~\ref{fig:zerocopy}, for \texttt{send} operation, \libipc{} invokes the kernel to get an encrypted physical address of send buffer and send the address to receiver via user-mode shared-memory queue.
The address is encrypted to prevent unsolicited mapping of arbitrary pages.
Because the sender may read the buffer after \texttt{send} or send the buffer to multiple receivers, the physical page cannot be remapped.
Additionally, \texttt{send} needs to write-protect the buffer because the receiver needs to read it.
On receiving side, \libipc{} invokes the kernel to remap the encrypted physical address to the application-provided receive buffer.
\texttt{recv} also needs to write-protect the buffer because it is shared by the sender and potentially multiple receivers.

A challenge arises when sender writes the buffer after \texttt{send}.
Existing zero-copy socket designs~\cite{thadani1995efficient,chu1996zero} use copy-on-write. Copy is required because the sender may read the non-written part of the page.
Because most applications reuse the buffer for subsequent send operations, copy-on-write is invoked in most cases, making zero-copy essentially useless on sender.
Our observation is that most applications overwrite entire pages of the send buffer via \texttt{recv} or \texttt{memcpy}, so it is unnecessary to copy old data when the first byte of the page is written.
Zero-copy \texttt{recv} remaps the buffer without triggering copy-on-write, so proxy applications can achieve zero copy.
For \texttt{memcpy}, we add preamble code to the function in both \libipc{} runtime and compiler inline library. If both source, destination addresses and the copy size are aligned to 4~KiB, and the destination address is write-protected by \libipc{}, the preamble code invokes the kernel to remap new pages to the destination address and disable write protection.
For compatibility, copy-on-write is still used for other write operations to protected buffers.

A second challenge is that page remapping requires the kernel to allocate and free pages for each \texttt{send} and \texttt{recv}. Page allocation in kernel acquires a global lock, therefore it is inefficient. Instead, \libipc{} manages a pool of free pages in each user-mode process.
We add to the kernel a system call to convert virtual addresses in the pool and encrypted physical addresses.
\libipc{} also tracks the origin of received zero-copy buffers.
After page remapping on sender \texttt{memcpy} and receiver \texttt{recv}, if the old physical page is from another process, \libipc{} sends a message to the origin process to return the buffer.


\section{Inter-Server Socket}
\label{sec:rdma}

Previous section discussed inter-process socket in a same server. For inter-server socket, \libipc{} determines whether or not the peer supports RDMA. If so, \libipc{} translate socket operations to one-sided RDMA \texttt{write} verbs. Otherwise, \libipc{} calls a light-weight user-mode TCP/IP stack to communicate with standard TCP/IP endpoints. In both cases, we achieve zero copy and scalability with number of threads and number of connections.

\subsection{Using RDMA Efficiently for Socket}

As stated in Sec.~\ref{subsec:challenges}, if we intuitively map each socket connection to an RDMA connection, due to NIC cache miss, the performance would degrade with more than a few hundreds of active connections. So we need to multiplex socket connections via an RDMA connection. %Mapping socket \texttt{send} and \texttt{recv} operations to two-sided RDMA \texttt{send} and \texttt{recv} verbs is also challenging due to mismatch in semantics.
Fortunately, our inter-process socket design can multiplex socket connections between two processes via a single shared-memory queue. To recap (Sec.~\ref{subsec:lockless-queue}), a shared-memory queue consists of two ring buffers, one for metadata from sender to receiver, the other for free data slots from receiver to sender.

To extend our intra-server design to inter-server, we only need to implement a ring buffer between each pair of communicating processes using RDMA verbs. The difference between intra-server and inter-server ring buffer is memory access latency. In our intra-server ring buffer design, sender checks \textit{isvalid} bit of each item in ring buffer to determine whether the queue is full, and receiver also checks \textit{isvalid} bit to determine whether the queue is empty. In RDMA setting, either sender or receiver needs to use RDMA to check \textit{isvalid} bit remotely, incurring one round-trip delay per enqueue or dequeue.

To avoid such delay, we design a \textit{credit-based ring buffer} for inter-server socket. Data of the ring buffer resides in receiver's main memory. Sender holds a tail pointer locally and receiver holds a head pointer locally. Sender maintains a number of \textit{credits}, indicating the number of unused items in ring buffer. When sender enqueues an item via RDMA \texttt{write}, it consumes a credit. When receiver dequeues an item, it increments a counter locally, and RDMA \texttt{write} a flag in sender's memory once the counter exceeds half the size of ring buffer. The sender regains credits upon detecting the flag. In this way, returning credits in batches amortizes RDMA messaging overhead for checking queue full. The only RDMA verb we use is one-sided posted \texttt{write}, so the ring buffer is wait-free on both sender and receiver. We did not use this design for intra-server because it doubles ring buffer size for a given queue capacity and affects memory locality.

Achieving zero copy RDMA is trivial given our inter-process design in Sec.~\ref{subsec:zerocopy}. We use physical addresses in RDMA verbs to eliminate memory registration and address translation overhead, as recommended by NIC documentation~\cite{mellanox}. During connection initialization, the receiver prepares a huge-page buffer for receiving zero-copy messages. The sender manages a pool of free pages in the receive buffer. Upon socket \texttt{send}, \libipc calls the kernel to get non-encrypted physical address of send virtual address. \libipc also allocates pages from receive buffer as remote address for RDMA \texttt{write}. The metadata message in ring buffer includes physical pages in receive buffer. Upon socket \texttt{recv}, \libipc calls the kernel maps physical pages in metadata message to receive virtual address. For security, kernel validates that page numbers are in the huge-page receive buffer. Same as intra-server zero-copy communication, when the receiver stops using the receive buffer, it is returned to the sender.


\subsection{Light-weight TCP/IP in User Space}

\sys{} needs to communicate with standard TCP/IP endpoints without RDMA support. There has been extensive work on user-space socket and TCP/IP stack in both academia~\cite{dunkels2001design,rizzo2012netmap,huang2017high} and industry~\cite{libvma,openonload,dbl}. However, most of these works do not optimize for a large number of concurrent connections, require locks for multi-thread applications, and do not support zero copy without application modification.

%A network stack is logically composed of three layers: the socket API for applications, TCP/IP protocol for reliable transmission and packet send/receive interface with NIC hardware. Our intra-server socket design in Sec.~\ref{sec:intra-server} applies directly to inter-server socket API. 

With a large number of concurrent connections, per-connection states in TCP/IP protocol stacks not only consumes host memory, but also reduces memory access locality. To save memory, light-weight TCP/IP stacks~\cite{dunkels2001design} do not pre-allocate send and receive buffers of TCP window size. But each connection still needs send and receive bitmaps to track out-of-order and lost packets, and selectively retransmit them. We modify LwIP~\cite{dunkels2001design} to incorporate MELO~\cite{lu2017memory}, a memory-efficient loss recovery mechanism that share bitmaps among connections. In this way, bitmap memory footprint is amortized to $\approx20$ bytes per connection.

For multi-thread applications, \libipc{} uses thread-local storage for states and file descriptors to eliminate locks. Each thread owns exclusive work request and completion queues to communicate with the NIC. In order to avoid TCP state sharing among threads, \libipc{} designates one thread with exclusive access to each TCP socket. If other threads access the file descriptor, it sends a takeover message to the owner thread, as in Sec.~\ref{subsubsec:fork_rdwr}.

To improve multi-process scalability of TCP servers, we leverage Receive-Side Scaling (RSS) in modern NICs to distribute incoming connections to the NIC queues of listening processes. The monitor process configures NIC indirection table~\cite{mellanox} when a process binds an external IP address. Each process maintains the TCP connection locally. However, listeners may need to migrate new connections under load imbalance. To this end, each listener maintains a \textit{backlog} of received new connections which has not been \texttt{accept}ed by the application. When the backlog overflows, it forwards the new connection to the monitor. When an idle process calls \texttt{accept} while backlog is empty, it requests from the monitor. Then, the overloaded process will forward received packets of the migrated connection to the idle process via shared-memory queue.

Supporting zero copy with existing applications requires removing two data copies on send and receive path. We remove data copy between application and \libipc{} in Sec.~\ref{subsec:zerocopy}. To remove data copy between \libipc{} and NIC, the payloads of sent and received packets need to align at 4~KiB page boundary. We leverage scatter-gather support in modern NICs~\cite{mellanox} to separate packet header from application payload. During initialization, \libipc{} queries IP and Ethernet MAC address from the kernel and constructs a packet header template. Upon socket \texttt{send}, \libipc{} copies the packet header template to a NIC send work request, then fills in the payload buffer address from application. In background, \libipc{} issues NIC receive work requests with a 54-byte buffer to hold exactly Ethernet, IPv4 and TCP headers, followed by a page-aligned buffer to hold payload. In corner cases where the received header length is not 54 bytes, \libipc{} reassembles the packet. Upon socket \texttt{recv}, the payload buffer is remapped to application.
