\section{Inter-Process Socket in a Server}
\label{sec:intra-server}

\subsection{Processes as Distributed System}
\label{subsec:socket-api}

How the socket works. A table show the process of using socket:

\begin{itemize}
	\item Process and thread creation. (fork, pthread\_create)
	\item Socket initialization.
	\item Connection setup.
	\item Data transmission.
\end{itemize}


Data structure in each process. Data structure in the monitor process.

Need a figure to show the lifecycle (message passing flow) of a socket connection. Three sub-figures:


	 \textbf{Socket initialization.}
	  
	 \textbf{Connection setup. (accept scheduling)}
	 
	 \textbf{Data transmission.}
	 
	 Discuss epoll.
\begin{itemize}
	\item Pick from the middle of the Q
	\item Starving (per fd slot)
	\item emergency Q
\end{itemize}

    \textbf{Close \& ACK}


\subsection{Scaling socket API}
\label{subsec:fork}

Process fork and thread creation are essential methods to enable parallelism in modern applications. 
However, as stated in \ref{subsec:challenges}, fork and thread creation pose the contention of logically shared data since it is a producer-consumer model and multiple consumer compete one shared data. With traditional mutual exclusion solution, the scalability of Socket is limited.

To tackle this issue, we make the following observation.
\begin{itemize}
	\item Fork system call and thread creation is low-frequency used in high performance applications.
	\item It is uncommon that several processes read data from one connection concurrently since Linux cannot guarantee atomicity of the bytes stream.
\end{itemize} 

Based on the observation above, our goal is to maximize the performance of the usual case while keep the maximum compatibility of the Linux socket semantics.

For the performance goal, base on the second observation. We propose the following requirements to maximize the performance of the usual case:
\begin{itemize}
 \item In multiple processes scenario, the performance of one-one connection ought to have the similar throughput and latency compared with that in single process scenario.
 \item For multiple sender and one receiver, the performance is supposed to scale, rather than dropped heavily compared with mutual exclusion solution.
 \item The previous access pattern of one connection by multiple processes shall not have follow-up effect to current performance. It means once the system achieves one-one connection no matter what happens before, the throughput is supposed to be lie near the bare shared memory lockless-queue.
\end{itemize}

For compatibility of the Linux semantics, the fundamental requirements is the order of the message. To be specific, the following two conditions need to be satisfied:
\begin{itemize}
\item For a specific consumer, the order of messages it from the same producer is supposed to be guaranteed.
\item The order of messages sent by one sender and received by multiple receiver should be guaranteed. e.g. For any messages D1, D2 sent by a sender S,  we guarantee that receiver R1 gets D1 and receiver R2 gets D2 if read called by R1 is prior to that by R2. 
\item Our design shall not run into deadlock. i.e. The existence of data of a certain connection and the existence of pending read function call cannot occur simultaneity.
\item Starvation is not supposed to happen in our system. i.e. One sender transmit data to two consumer, but only one receiver can get the message while the other one keeps waiting.
\end{itemize}

Briefly, our design of multiple processing can be divided to three parts: a) read and write operation b) fork and pthread\_create function call (i.e. new processes add to the existing connection). c) close function call (i.e. existing connection is closed, all the processes leave the connection).


\subsubsection{Read/Write operation}

In this paragraph, we assume that the connection is already setup and the number of processes involved in this connection is stable. In order to achieve high throughput, we leverage lock-free queue to enable one-one connection. For multiple process on one connection, in order to achieve high scalability, we create separate queues for each sender and receiver and the queues build a bipartite graph between the sender and the receiver.For one sender, it pairs to a specific receiver who will receive and only transmit data to that receiver. The receiver round robin poll the messages from all the queues connected to senders. Figure \ref{fig:fork-bipartitegraph} shows a sample of the shared-memory buffers between senders and receivers for one connection. 

In order to avoid deadlock, how to choose the specific receiver of the sender is a key challenge since the receiver chose by the sender may not handle the data in that connection while other receivers may under starvation. Based on our observation that usually only one receiver retrieves data from the sender side, we could simply let the sender transmit the data to the receiver who previously requested for it i.e. the receiver which calls read first send a "takeover message" to sender and sender begins to transmit byte stream to that receiver. In common cases, the performance could be achieved as high as one-one connection since the sender only send the data to one receiver and no contention happens.

However, in this design, in order to satisfy the order requirements, how to deal with the data already in the queue while a different receiver sends "takeover message" is especially challenging.  We need to ensure that all the old data is read by the newly receiver first, and then the new data of sender can be sent to the that receiver. To tackle this problem, sender side first send a request to the old receiver to request it return all the unconsumed messages in queue to sender and sender retransmit them to new receiver before new data by the sender is pushed in to the new receiver to avoid lock contention between the sender and the old receiver.

Another detail is that, in order to reduce the overhead of the "takeover message", receiver only send "takeover message" to those senders which does not send data to it. In order to let the receiver know whether itself is designated by the sender, the sender keeps a bit flag in the shared memory between it and each receiver.  Only one of these flags, which is in where sender gets the "takeover message" lastly is set to one while other flags are set to zero. When sender notices a "takeover message", it changes the flag linked with the new receiver to one and set the original flag to zero.


\begin{figure}[t]
	\centering
	\includegraphics[width=0.3\textwidth]{images/fixme}
	\caption{This figure shows a stable connection handled by multiple senders and receivers.}
	\label{fig:fork-bipartitegraph}
\end{figure}

\subsubsection{Fork/Thread creation}
For fork, the instinctive way is to create a new queue for the newly created process. 
\subsubsection{Close of a connection}
  
Key point: Coordination in shared socket.

Clock pointer (simple)

Takeover (compare with \ref{subsec:socket-api})

Read Lock

Tree

Fork \& Close interleaving

\subsection{Shared-Memory Queue}

x86-TSO~\cite{sewell2010x86}, intel manual~\cite{intel-manual}

\subsection{Process Multiplexing}
\label{subsec:epoll}


Message passing may wait too long.
Signal mechanism. Signal process after waiting until timeout.

Monitor detect process death (via control socket SIGHUP) and notify endpoints.

Blocking operation: sched\_yield.


\subsection{Zero Copy}
\label{subsec:zerocopy}

\begin{figure}[t]
	\centering
	\includegraphics[width=0.3\textwidth]{images/fixme}
	\caption{Zero-copy theory of operation.}
	\label{fig:zerocopy}
\end{figure}

The main challenge for zero copy is to maintain the semantics of socket API. The sender may write the send buffer after non-blocking \texttt{send}, and the receiver does not know the receive buffer before \texttt{recv}.
Fortunately, the virtual memory provides a layer of indirection, so we can remap virtual address of a buffer to another physical page, if the data occupies entire 4~KiB pages.
To this end, we wrap around \texttt{malloc} function and allocate 4~KiB aligned addresses for large allocations, so most buffers will align to page boundary.
If the size of send message is not a multiple of 4~KiB, the last chunk of data is copied on \texttt{send} and \texttt{recv}.

As shown in Figure~\ref{fig:zerocopy}, for \texttt{send} operation, \libipc{} invokes the kernel to get an encrypted physical address of send buffer and send the address to receiver via user-mode shared-memory queue.
The address is encrypted to prevent unsolicited mapping of arbitrary pages.
Because the sender may read the buffer after \texttt{send} or send the buffer to multiple receivers, the physical page cannot be remapped.
Additionally, \texttt{send} needs to write-protect the buffer because the receiver needs to read it.
On receiving side, \libipc{} invokes the kernel to remap the encrypted physical address to the application-provided receive buffer.
\texttt{recv} also needs to write-protect the buffer because it is shared by the sender and potentially multiple receivers.

A challenge arises when sender writes the buffer after \texttt{send}.
Existing zero-copy socket designs~\cite{thadani1995efficient,chu1996zero} use copy-on-write. Copy is required because the sender may read the non-written part of the page.
Because most applications reuse the buffer for subsequent send operations, copy-on-write is invoked in most cases, making zero-copy essentially useless on sender.
Our observation is that most applications overwrite entire pages of the send buffer via \texttt{recv} or \texttt{memcpy}, so it is unnecessary to copy old data when the first byte of the page is written.
Zero-copy \texttt{recv} remaps the buffer without triggering copy-on-write, so proxy applications can achieve zero copy.
For \texttt{memcpy}, we add preamble code to the function in both \libipc{} runtime and compiler inline library. If both source, destination addresses and the copy size are aligned to 4~KiB, and the destination address is write-protected by \libipc{}, the preamble code invokes the kernel to remap new pages to the destination address and disable write protection.
For compatibility, copy-on-write is still used for other write operations to protected buffers.

A second challenge is that page remapping requires the kernel to allocate and free pages for each \texttt{send} and \texttt{recv}. Page allocation in kernel acquires a global lock, therefore it is inefficient. Instead, \libipc{} manages a pool of free pages in each user-mode process.
We add to the kernel a system call to convert virtual addresses in the pool and encrypted physical addresses.
\libipc{} also tracks the origin of received zero-copy buffers.
After page remapping on sender \texttt{memcpy} and receiver \texttt{recv}, if the old physical page is from another process, \libipc{} sends a message to the origin process to return the buffer.


\section{Utilizing RDMA for Inter-server Socket}
\label{sec:rdma}

Remember: if the other endpoint is not RDMA capable, use libvma.

 It reserves the send buffer after \texttt{send} and releases it after send completion notification.
The application also delegates non-blocking receive operations along with receive buffers, so the NIC can DMA received data directly to the receive buffers, then notify the application that data is ready.